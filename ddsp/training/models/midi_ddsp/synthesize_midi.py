"""Synthesize any MIDI file using MIDI-DDSP through command line."""
import tensorflow as tf
import numpy as np
import pretty_midi
import os
import argparse
import glob
from tqdm import tqdm

from data_handling.instrument_name_utils import INST_NAME_TO_MIDI_PROGRAM_DICT, \
  MIDI_PROGRAM_TO_INST_ID_DICT
from utils.midi_synthesis_utils import note_list_to_sequence, \
  expression_generator_output_to_conditioning_df, \
  batch_conditioning_df_to_audio
from utils.audio_io import save_wav
from utils.training_utils import get_hp
from utils.inference_utils import ensure_same_length
from hparams_synthesis_generator import hparams as hp
from midi_ddsp.get_model import get_model, get_fake_data
import train_expression_generator
from midi_ddsp.language_model import InterpCondAutoregressiveRNN


def synthesize_midi(synthesis_generator, expression_generator, midi_file,
                    pitch_offset=0, speed_rate=1.0,
                    output_dir=r'./', fs=250, sample_rate=16000,
                    use_fluidsynth=True,
                    sf2_path='/usr/share/sounds/sf2/FluidR3_GM.sf2',
                    display_progressbar=True):
  """
  Synthesize a midi file using MIDI-DDSP.
  Args:
      synthesis_generator: The instance of a synthesis generator.
      expression_generator: The instance of a expression generator.
      midi_file: The path to the MIDI file.
      pitch_offset: Pitch in semitone to transpose.
      speed_rate: The speed to synthesize the MIDI file.
      output_dir: The directory for output audio.
      fs: Frame rate for synthesis generator.
      sample_rate: Sample rate for synthesizing the audio.
      use_fluidsynth: Whether to use FluidSynth for synthesizing instruments
      that are not available in MIDI-DDSP.
      sf2_path: The path to a sf2 soundfont file used for FluidSynth.
      display_progressbar: Whether to display progress bar.

  Returns: A dict of output:
          'mix_audio': mix audio,
          'stem_audio': stem audios,
          'part_synth_by_model': list of part numbers that are synthesized
          by MIDI-DDSP,
          'midi_control_params': control parameters generated by MIDI-DDSP,
          'midi_synth_params': synth parameters generated by MIDI-DDSP,,
          'conditioning_df': note expressions predicted by expression generator
          in the format of DataFrame,
  """
  # Create output folder under output directory.
  filename = os.path.splitext(os.path.basename(midi_file))[0]
  output_dir = os.path.join(output_dir, filename)
  os.makedirs(output_dir, exist_ok=True)

  # Get all the midi program in URMP dataset excluding guitar.
  allowed_midi_program = [v for v in INST_NAME_TO_MIDI_PROGRAM_DICT.values()][
                         :-1]
  midi_data = pretty_midi.PrettyMIDI(midi_file)
  instrument_id_all = []
  conditioning_df_all = []
  part_synth_by_model = []
  midi_audio_all = {}

  # For each part, predict expressions using MIDI-DDSP,
  # or synthesize using FluidSynth.
  for part_number, instrument in enumerate(midi_data.instruments):
    midi_program = instrument.program
    if midi_program in allowed_midi_program:
      note_sequence = note_list_to_sequence(instrument.notes, fs=fs,
                                            pitch_offset=pitch_offset,
                                            speed_rate=speed_rate)
      instrument_id = tf.constant([MIDI_PROGRAM_TO_INST_ID_DICT[midi_program]])
      instrument_id_all.append(instrument_id)
      note_sequence['instrument_id'] = instrument_id
      expression_generator_outputs = expression_generator(note_sequence,
                                                          out=None,
                                                          training=False)
      conditioning_df = expression_generator_output_to_conditioning_df(
        expression_generator_outputs['output'], note_sequence)
      conditioning_df_all.append(conditioning_df)
      part_synth_by_model.append(part_number)
    elif use_fluidsynth:
      print(
        f'Instrument {part_number} for {midi_file} has a midi program '
        f'of {midi_program} which cannot be synthesized by model. '
        f'Using fluidsynth instead.')

      fluidsynth_wav_r3 = instrument.fluidsynth(sample_rate, sf2_path=sf2_path)
      fluidsynth_wav_r3 *= 0.25  # * 0.25 for lower volume
      midi_audio_all[part_number] = fluidsynth_wav_r3

  # Synthesize audio in batch using synthesis generator.
  if len(conditioning_df_all) > 0:
    midi_audio, midi_control_params, midi_synth_params = \
      batch_conditioning_df_to_audio(
        synthesis_generator,
        conditioning_df_all,
        instrument_id_all,
        display_progressbar=display_progressbar)

    for i in range(midi_audio.shape[0]):
      part_number = part_synth_by_model[i]
      midi_audio_all[part_number] = midi_audio[i].numpy()
  else:
    midi_control_params = None
    midi_synth_params = None

  # Sorting out and save the wav.
  for part_number, instrument in enumerate(midi_data.instruments):
    midi_program = instrument.program
    if midi_program in allowed_midi_program:
      audio = midi_audio_all[part_number]
      save_wav(audio,
               os.path.join(
                 output_dir,
                 f'{part_number}_{midi_program}.wav'),
               16000)
    elif use_fluidsynth:
      audio = midi_audio_all[part_number]
      save_wav(audio,
               os.path.join(
                 output_dir,
                 f'{part_number}_{midi_program}_fluidsynth.wav'),
               16000)

  # If there is audio synthesized, mix the audio and return the output.
  if midi_audio_all:
    midi_audio_mix = np.sum(
      np.stack(ensure_same_length(
        [a.astype(np.float) for a in midi_audio_all.values()], axis=0),
        axis=-1),
      axis=-1)
    save_wav(midi_audio_mix, os.path.join(output_dir, 'mix.wav'), 16000)
    output = {
      'mix_audio': midi_audio_mix,
      'stem_audio': midi_audio_all,
      'part_synth_by_model': part_synth_by_model,
      'midi_control_params': midi_control_params,
      'midi_synth_params': midi_synth_params,
      'conditioning_df': conditioning_df_all,
    }
  else:
    output = None

  return output


if __name__ == '__main__':
  parser = argparse.ArgumentParser(
    description='Synthesize MIDI files using MIDI-DDSP.')
  parser.add_argument('--midi_dir', type=str, default=None,
                      help='The directory containing MIDI files.')
  parser.add_argument('--midi_path', type=str, default=None,
                      help='The path to a MIDI file.')
  parser.add_argument('--pitch_offset', type=int, default=0,
                      help='Pitch offset to transpose in semitone.')
  parser.add_argument('--speed_rate', type=float, default=1.0,
                      help='The speed to synthesize the MIDI file(s).')
  parser.add_argument('--sf2_path', type=str,
                      default=None,  # '/usr/share/sounds/sf2/FluidR3_GM.sf2'
                      help='The path to a sf2 soundfont file.')
  parser.add_argument('--output_dir', type=str, default=None,
                      help='The directory for output audio.')
  parser.add_argument('--use_fluidsynth', action='store_true',
                      help='Use FluidSynth to synthesize the midi instruments '
                           'that are not contained in MIDI-DDSP.')
  parser.add_argument('--synthesis_generator_weight_path', type=str,
                      default=None,
                      help='The path to the synthesis generator weights. '
                           'It is not a specific file path but an index path. '
                           'See https://www.tensorflow.org/guide/checkpoint'
                           '#restore_and_continue_training.')
  parser.add_argument('--expression_generator_weight_path', type=str,
                      default=None,
                      help='The path to the expression generator weights. '
                           'It is not a specific file path but an index path. '
                           'See https://www.tensorflow.org/guide/checkpoint'
                           '#restore_and_continue_training.')
  args = parser.parse_args()

  synthesis_generator_path = args.synthesis_generator_weight_path
  hp_dict = get_hp(
    os.path.join(os.path.dirname(synthesis_generator_path), 'train.log'))
  for k, v in hp_dict.items():
    setattr(hp, k, v)
  synthesis_generator = get_model(hp)
  _ = synthesis_generator._build(get_fake_data(hp))
  synthesis_generator.load_weights(synthesis_generator_path)

  n_out = 6
  expression_generator = InterpCondAutoregressiveRNN(n_out=n_out, nhid=128)
  fake_data = train_expression_generator.get_fake_data(n_out)
  _ = expression_generator(fake_data['cond'], out=fake_data['target'],
                           training=True)
  expression_generator_path = args.expression_generator_weight_path
  expression_generator.load_weights(expression_generator_path)

  if args.midi_dir and args.midi_path:
    raise RuntimeWarning(
      'Both midi_dir and midi_path are provided. Will use midi_dir.')
  elif not args.midi_dir and not args.midi_path:
    raise ValueError('None of midi_dir or midi_path is provided. '
                     'Please provide at least one of midi_dir or midi_path.')
  elif args.midi_dir:
    midi_file_list = glob.glob(args.midi_dir + '/*.mid')
    if len(midi_file_list) == 0:
      raise FileNotFoundError('No midi files found in the directory.')
    for midi_file in tqdm(midi_file_list):
      output = synthesize_midi(
        synthesis_generator,
        expression_generator,
        midi_file,
        pitch_offset=args.pitch_offset,
        speed_rate=args.speed_rate,
        output_dir=args.output_dir,
        sf2_path=args.sf2_path,
        use_fluidsynth=args.use_fluidsynth,
        display_progressbar=False
      )
  elif args.midi_path:
    output = synthesize_midi(
      synthesis_generator,
      expression_generator,
      args.midi_path,
      pitch_offset=args.pitch_offset,
      speed_rate=args.speed_rate,
      output_dir=args.output_dir,
      sf2_path=args.sf2_path,
      use_fluidsynth=args.use_fluidsynth,
      display_progressbar=True
    )
